{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b523ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "\n",
    "# For GPU server\n",
    "#path = '/lfs/mead9103.ui/NN_Training/'\n",
    "#path = ''\n",
    "\n",
    "def video_to_CSV(filename, frames = 240):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open camera for video %s\" % filename)\n",
    "        return\n",
    "\n",
    "    # Define the keypoint mapping for this OpenPose body_25 model\n",
    "    keypoints_mapping = {\n",
    "        0:  \"Nose\", 1:  \"Neck\", 2:  \"RShoulder\", 3:  \"RElbow\", 4:  \"RWrist\", 5:  \"LShoulder\", 6:  \"LElbow\",\n",
    "        7:  \"LWrist\", 8:  \"MidHip\", 9:  \"RHip\", 10: \"RKnee\", 11: \"RAnkle\", 12: \"LHip\", 13: \"LKnee\",\n",
    "        14: \"LAnkle\", 15: \"REye\", 16: \"LEye\", 17: \"REar\", 18: \"LEar\", 19: \"LBigToe\", 20: \"LSmallToe\",\n",
    "        21: \"LHeel\", 22: \"RBigToe\", 23: \"RSmallToe\", 24: \"RHeel\"\n",
    "    }\n",
    "    #load the model\n",
    "    net = cv2.dnn.readNetFromCaffe('pose_deploy.prototxt', 'pose_iter_584000.caffemodel')\n",
    "\n",
    "    #Write frame information of joint locations into a csv file\n",
    "    f = open(filename + \".csv\", 'w', newline='')\n",
    "    w = csv.writer(f)\n",
    "    #for keypoint, label in keypoints_mapping:\n",
    "        #w.write(str(keypoints_mapping.items())\n",
    "    #w.writerow(keypoints_mapping.values())\n",
    "    \n",
    "    def framestep(cap):\n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        new_vid = []\n",
    "        # Keep stepsize as a float, consider someday skipping frame 0 since it's unlikely to be useful\n",
    "        stepsize = (frame_count - 1) / (frames - 1) # subtract 1 to account for frame 0\n",
    "        print(\"Video: %s, frames to be analyzed: %d (%d / %.2f)\" % (filename, frames, frame_count, stepsize))\n",
    "        curr_frame = 0\n",
    "        i = 0 # float index of next frame\n",
    "        \n",
    "        # Loop until the whole video has been read, or the requested number of frames are reached\n",
    "        while curr_frame < frame_count:\n",
    "            ret, frame = cap.read()\n",
    "            if curr_frame == int(i):\n",
    "                print(\"Starting frame: %d (index %.2f)\" % (curr_frame, i))\n",
    "                new_vid.append(pose(frame))\n",
    "                i += stepsize\n",
    "            curr_frame += 1\n",
    "        return new_vid\n",
    "        \n",
    "    def squarify(frame):\n",
    "        height, width, _ = frame.shape\n",
    "        min_dim = min(height, width)\n",
    "\n",
    "        # Calculate the cropping dimensions\n",
    "        crop_height = (height - min_dim) // 2\n",
    "        crop_width = (width - min_dim) // 2\n",
    "\n",
    "        # Crop the image equally from both sides to make it a square\n",
    "        return frame[crop_height:crop_height+min_dim, crop_width:crop_width+min_dim] , min_dim\n",
    "\n",
    "    def pose(frame):\n",
    "        frame, size = squarify(frame)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255, (size, size),\n",
    "                                (0, 0, 0), swapRB=False, crop=True)\n",
    "\n",
    "        # run forward pass to get the pose estimation\n",
    "        net.setInput(blob)\n",
    "        output = net.forward()\n",
    "        \n",
    "        # Extract joint locations\n",
    "        joint_locations = []\n",
    "        csv_joint_locations = []\n",
    "\n",
    "        for i in range(len(keypoints_mapping)): #-1 bc we dont want point for the background\n",
    "            keypoint = output[0, i, :, :]\n",
    "            min_val, confidence, min_loc, point = cv2.minMaxLoc(keypoint)\n",
    "\n",
    "            #if confidence > 0.1:  # can adjust the confidence threshold if needed ???\n",
    "            joint_locations.append((8 * int(point[0]), 8 * int(point[1]), 0)) #for testing/human readable\n",
    "            csv_joint_locations.append(8 * int(point[0])) #to be printed into csv\n",
    "            csv_joint_locations.append(8 * int(point[1])) #to be printed into csv\n",
    "            csv_joint_locations.append(0) #to be printed into csv\n",
    "            '''else:\n",
    "                joint_locations.append(None) #for testing/human readable\n",
    "                csv_joint_locations.append(8 * int(point[0])) #to be printed into csv\n",
    "                csv_joint_locations.append(8 * int(point[1])) #to be printed into csv\n",
    "            '''\n",
    "        #joint_locations contains the locations of the detected joints and corresponding index\n",
    "\n",
    "        '''for location in joint_locations:\n",
    "            if location:\n",
    "                x, y, index = location\n",
    "                cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "                #cv2.putText(image, str(index), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        '''        \n",
    "        #print joint locations into a csv file\n",
    "        w.writerow(csv_joint_locations)\n",
    "        \n",
    "        return frame\n",
    "\n",
    "    #write the information + circles onto each frame and pop up a window for each frame\n",
    "    my_video = framestep(cap)\n",
    "    size = my_video[0].shape[1], my_video[0].shape[0]\n",
    "    print(size)\n",
    "    '''out = cv2.VideoWriter(\"real.avi\", cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "\n",
    "    for i in range(len(my_video)):\n",
    "        out.write(my_video[i])\n",
    "        cv2.imshow(\"video\", my_video[i])\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    '''\n",
    "    cap.release()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e14e4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def replace_outliers(data, window_size=5, threshold=2.0):\n",
    "    \"\"\"\n",
    "    Replace outliers in each column with the average of adjacent points within a specified window.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pandas DataFrame\n",
    "    - window_size: int, the size of the window for calculating the average (default is 5)\n",
    "    - threshold: float, the threshold for identifying outliers (default is 2.0)\n",
    "\n",
    "    Returns:\n",
    "    - data: pandas DataFrame, with outliers replaced\n",
    "    \"\"\"\n",
    "    for column_name in data.columns:\n",
    "        x = data[column_name].values\n",
    "\n",
    "        # Identify outliers based on the average of points within the window\n",
    "        for i in range(window_size, len(x) - window_size):\n",
    "            window_avg = x[i - window_size:i + window_size + 1].mean()\n",
    "            if np.abs(x[i] - window_avg) > threshold * x.std():\n",
    "                x[i] = window_avg\n",
    "\n",
    "        # update the dataframe\n",
    "        data[column_name] = x\n",
    "    return data\n",
    "\n",
    "def moving_average(data):\n",
    "    smoothed_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len(data.columns)):\n",
    "        x_col = data.columns[i]\n",
    "\n",
    "        x = data[x_col].values\n",
    "\n",
    "        # Apply the new weights for the moving average\n",
    "        x_smoothed = 0.1 * pd.Series(x).shift(-1, fill_value=x[-1]).values + 0.8 * x + 0.1 * pd.Series(x).shift(1, fill_value=x[0]).values\n",
    "        smoothed_data[x_col] = x_smoothed\n",
    "\n",
    "    return smoothed_data\n",
    "\n",
    "def smooth_and_save(input_file):\n",
    "    # Load your CSV data into a pandas DataFrame\n",
    "    df = pd.read_csv(input_file, header=None)\n",
    "\n",
    "    replace_outliers(df)\n",
    "    # adjust each point with a moving average of the previous 2 points\n",
    "    smoothed_data = moving_average(df)\n",
    "\n",
    "    # Save the smoothed data to a new CSV file\n",
    "    output_file = input_file.replace('.csv', '_smoothed.csv')\n",
    "    smoothed_data.to_csv(output_file, index=False, header = False)\n",
    "    print(f'Smoothed data saved to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44b1a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#video_to_CSV(\"Molly_Correct_DeepSquat.mp4\", frames_to_analyze) #get the data for correct squat\n",
    "#video_to_CSV(\"Molly_Incorrect_DeepSquat.mp4\", frames_to_analyze) #get the data for incorrect squat\n",
    "\n",
    "#smooth_and_save(\"Molly_Correct_DeepSquat.mp4.csv\")\n",
    "#smooth_and_save(\"Molly_Incorrect_DeepSquat.mp4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "890358e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data\n",
    "\n",
    "def reshapeUserData(filename):\n",
    "    df1 = pd.read_csv(path + filename + \"_smoothed.csv\", header=None)\n",
    "    raw_data = df1.to_numpy()\n",
    "    #print(raw_data)\n",
    "    raw_data_1 = raw_data.reshape(75 * frames_to_analyze)\n",
    "    raw_data_2 = raw_data_1.reshape(75, frames_to_analyze, order = 'F')\n",
    "    data_mean = np.mean(raw_data_2, axis = 0)\n",
    "    centered_data = raw_data_2 - data_mean\n",
    "    scaling_value = np.ceil(max(np.max(centered_data), abs(np.min(centered_data))))\n",
    "    data_correct = centered_data / scaling_value\n",
    "    #print(raw_data_2)\n",
    "    \n",
    "    #open and write reshaped data to a csv\n",
    "    f = open(path + 'filename', 'w', newline = '')\n",
    "    w = csv.writer(f)\n",
    "    np.apply_along_axis(w.writerow, axis = 1, arr = data_correct)\n",
    "    f.close()\n",
    "\n",
    "#incorrect reshape\n",
    "#Inc = pd.read_csv(\"Molly_Incorrect_DeepSquat.mp4_smoothed.csv\", header=None)\n",
    "#Inc_raw_data = Inc.to_numpy()\n",
    "#Inc_raw_data_1 = Inc_raw_data.reshape(75 * frames_to_analyze)\n",
    "#Inc_raw_data_2 = Inc_raw_data_1.reshape(75, frames_to_analyze, order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "655a36ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInc_data_mean = np.mean(Inc_raw_data_2, axis = 0)\\n\\n\\ncentered_data_inc = Inc_raw_data_2 - Inc_data_mean\\n\\n# Scale the data between -1 and 1\\n\\n\\n# Scale the incorrect data between -1 and 1\\nscaling_value_inc = np.ceil(max(np.max(centered_data_inc), abs(np.min(centered_data_inc))))\\ndata_incorrect = centered_data_inc / scaling_value_inc\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Inc_data_mean = np.mean(Inc_raw_data_2, axis = 0)\n",
    "\n",
    "\n",
    "centered_data_inc = Inc_raw_data_2 - Inc_data_mean\n",
    "\n",
    "# Scale the data between -1 and 1\n",
    "\n",
    "\n",
    "# Scale the incorrect data between -1 and 1\n",
    "scaling_value_inc = np.ceil(max(np.max(centered_data_inc), abs(np.min(centered_data_inc))))\n",
    "data_incorrect = centered_data_inc / scaling_value_inc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10662ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nf = open(path + 'Molly_data_incorrect.csv', 'w', newline = '')\\nw = csv.writer(f)\\nnp.apply_along_axis(w.writerow, axis = 1, arr = data_incorrect)\\n\\nf.close()\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "f = open(path + 'Molly_data_incorrect.csv', 'w', newline = '')\n",
    "w = csv.writer(f)\n",
    "np.apply_along_axis(w.writerow, axis = 1, arr = data_incorrect)\n",
    "\n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c44b191f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (4067252534.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Molly Meadows\\AppData\\Local\\Temp\\ipykernel_30452\\4067252534.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    path = \"C:\\Users\\Molly Meadows\\OneDrive - University of Idaho\\Documents\\2023-2024\\Capstone Project\\26-Physical-Rehabilitation\\Design Validation\\Testing_Videos\\\"\u001b[0m\n\u001b[1;37m                                                                                                                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "features = 75\n",
    "frames_to_analyze = 40\n",
    "path = \"C:/Users/Molly Meadows/OneDrive - University of Idaho/Documents/2023-2024/Capstone Project/26-Physical-Rehabilitation/Design Validation/Testing_Videos\\\"\n",
    "\n",
    "def analyzeUserVideo(filename):\n",
    "    video_to_CSV(filename, frames_to_analyze) #get the data for correct squat\n",
    "    smooth_and_save(path + filename)\n",
    "    reshapeUserData(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c57c8f6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"C:/Users/Molly Meadows/OneDrive - University of Idaho/Documents/2023-2024/Capstone Project/26-Physical-Rehabilitation/Design Validation/Testing_Videos/pose_deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30452\\3676822995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalyzeUserVideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"VID_20240305_155018185.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30452\\3044983943.py\u001b[0m in \u001b[0;36manalyzeUserVideo\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0manalyzeUserVideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mvideo_to_CSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes_to_analyze\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get the data for correct squat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0msmooth_and_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mreshapeUserData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30452\\1341968487.py\u001b[0m in \u001b[0;36mvideo_to_CSV\u001b[1;34m(filename, frames)\u001b[0m\n\u001b[0;32m     22\u001b[0m     }\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNetFromCaffe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'pose_deploy.prototxt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'pose_iter_584000.caffemodel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#Write frame information of joint locations into a csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\caffe\\caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"C:/Users/Molly Meadows/OneDrive - University of Idaho/Documents/2023-2024/Capstone Project/26-Physical-Rehabilitation/Design Validation/Testing_Videos/pose_deploy.prototxt\" in function 'cv::dnn::ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "analyzeUserVideo(\"VID_20240305_155018185.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b4c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
